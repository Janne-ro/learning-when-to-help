{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbb71650",
   "metadata": {},
   "source": [
    "# Code to train the RL agent\n",
    "\n",
    "This code trains a PPO [stablebaseline3 RL-agent](https://github.com/DLR-RM/stable-baselines3) to learn an ideal policy to decide when to allow the student to use GenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a38f2a7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be71ad03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 0 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 5 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 10 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 15 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 20 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 25 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 30 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 35 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 40 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 45 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 50 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 55 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 60 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 65 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 70 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 75 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 80 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 85 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 90 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 95 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 100 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 105 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 110 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 115 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 120 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 125 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 130 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 135 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 140 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 145 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 150 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 0 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 155 | Next try at: 157.78721422972905\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 1 | Action taken: 0\n",
      "Student answered correctly\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 160 | Next try at: 208.6565008962658\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: 9.9\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 1 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 165 | Next try at: 208.6565008962658\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 1 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 170 | Next try at: 208.6565008962658\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 1 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 175 | Next try at: 208.6565008962658\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 1 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 180 | Next try at: 208.6565008962658\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 1 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 185 | Next try at: 208.6565008962658\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 1 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 190 | Next try at: 208.6565008962658\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 1 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 195 | Next try at: 208.6565008962658\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 1 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 200 | Next try at: 208.6565008962658\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 1 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 205 | Next try at: 208.6565008962658\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student answered correctly\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 210 | Next try at: 266.7585033139707\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: 9.9\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 215 | Next try at: 266.7585033139707\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 220 | Next try at: 266.7585033139707\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 225 | Next try at: 266.7585033139707\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 230 | Next try at: 266.7585033139707\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 235 | Next try at: 266.7585033139707\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 240 | Next try at: 266.7585033139707\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 245 | Next try at: 266.7585033139707\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 250 | Next try at: 266.7585033139707\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 255 | Next try at: 266.7585033139707\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 260 | Next try at: 266.7585033139707\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 265 | Next try at: 266.7585033139707\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 0, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student answered wrongly\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 270 | Next try at: 290.44583539702865\n",
      "Failed attempts on current task: 1\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 275 | Next try at: 290.44583539702865\n",
      "Failed attempts on current task: 1\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 280 | Next try at: 290.44583539702865\n",
      "Failed attempts on current task: 1\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 285 | Next try at: 290.44583539702865\n",
      "Failed attempts on current task: 1\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 2 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 1 | Last metatask: None\n",
      "Time: 290 | Next try at: 290.44583539702865\n",
      "Failed attempts on current task: 1\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: 0.0\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 0 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 5 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 10 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 15 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 20 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 25 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 30 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 35 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 40 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 45 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 50 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 55 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 60 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 65 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 70 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 75 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 80 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 85 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 90 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 95 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 3 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 100 | Next try at: 100.99262649242789\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 4 | Action taken: 0\n",
      "Student answered correctly\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 105 | Next try at: 155.28422342111543\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: 9.9\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 4 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 110 | Next try at: 155.28422342111543\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 4 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 115 | Next try at: 155.28422342111543\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 4 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 120 | Next try at: 155.28422342111543\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 4 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 125 | Next try at: 155.28422342111543\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 4 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 130 | Next try at: 155.28422342111543\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 4 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 135 | Next try at: 155.28422342111543\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 4 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 140 | Next try at: 155.28422342111543\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 4 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 145 | Next try at: 155.28422342111543\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 4 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 150 | Next try at: 155.28422342111543\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 4 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 155 | Next try at: 155.28422342111543\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 5 | Action taken: 0\n",
      "Student answered correctly\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 160 | Next try at: 201.15780029969721\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: 9.9\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 5 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 165 | Next try at: 201.15780029969721\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 5 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 170 | Next try at: 201.15780029969721\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 5 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 175 | Next try at: 201.15780029969721\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 5 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 180 | Next try at: 201.15780029969721\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 5 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 185 | Next try at: 201.15780029969721\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 5 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 190 | Next try at: 201.15780029969721\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 5 | Action taken: 0\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 195 | Next try at: 201.15780029969721\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': False, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -0.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "======================================================================\n",
      "STEP START — Current Task: 5 | Action taken: 1\n",
      "Student did not answer in this iteration\n",
      "Metatask: Task 2 | Last metatask: Task 1\n",
      "Time: 200 | Next try at: 201.15780029969721\n",
      "Failed attempts on current task: 0\n",
      "Failed attempts per metatask: {'Task 1': 1, 'Task 2': 0, 'Task 3': 0}\n",
      "Used GenAI per metatask: {'Task 1': False, 'Task 2': True, 'Task 3': False}\n",
      "======================================================================\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Reward for this action: -5.1\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "svmem(total=16952647680, available=8158994432, percent=51.9, used=8793653248, free=8158994432)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports \n",
    "from environment import LearningEnv     # your environment file\n",
    "from gymnasium.envs.registration import register\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab799ed",
   "metadata": {},
   "source": [
    "## 1. Register the custom environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ab3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "register(\n",
    "    id=\"MyEnv-v0\",\n",
    "    entry_point=\"environment:LearningEnv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa7af92",
   "metadata": {},
   "source": [
    "## 2. Create and check the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd2b5be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MyEnv-v0\")\n",
    "check_env(env)        #recommended by stable-baselines3 for custom envs\n",
    "env = Monitor(env)    #logs rewards, episode lengths, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d88c01",
   "metadata": {},
   "source": [
    "## 3. Create PPO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aebe64ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./ppo_logs/\",   # tensorboard --logdir ppo_logs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e19f1c4",
   "metadata": {},
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "089b6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir ppo_logs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6182dd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_logs/PPO_16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 6.22     |\n",
      "|    ep_rew_mean     | -250     |\n",
      "| time/              |          |\n",
      "|    fps             | 1749     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.17        |\n",
      "|    ep_rew_mean          | -244        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1253        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010578712 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | -0.00923    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+04    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 2.29e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.61        |\n",
      "|    ep_rew_mean          | -238        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1245        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015477381 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.648      |\n",
      "|    explained_variance   | -0.0352     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.54e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 1.77e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 11.5       |\n",
      "|    ep_rew_mean          | -234       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1223       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 6          |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02174415 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.573     |\n",
      "|    explained_variance   | -0.0125    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.94e+03   |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0267    |\n",
      "|    value_loss           | 1.29e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 18         |\n",
      "|    ep_rew_mean          | -215       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1235       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02102188 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.465     |\n",
      "|    explained_variance   | -0.0048    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.21e+03   |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0253    |\n",
      "|    value_loss           | 9.04e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.7        |\n",
      "|    ep_rew_mean          | -188        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1238        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026208427 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | -0.00213    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 4.65e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.7        |\n",
      "|    ep_rew_mean          | -149        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1243        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059308156 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.185      |\n",
      "|    explained_variance   | -0.000924   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 715         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    value_loss           | 2.13e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 61.7         |\n",
      "|    ep_rew_mean          | -108         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1249         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007476595 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.107       |\n",
      "|    explained_variance   | -0.000188    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.94e+03     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    value_loss           | 2.02e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 78            |\n",
      "|    ep_rew_mean          | -67.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1258          |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041377472 |\n",
      "|    clip_fraction        | 0.00698       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.101        |\n",
      "|    explained_variance   | -9.55e-05     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 939           |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.00304      |\n",
      "|    value_loss           | 1.79e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.9         |\n",
      "|    ep_rew_mean          | -42.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1265         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010161081 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0945      |\n",
      "|    explained_variance   | -5.39e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 565          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    value_loss           | 2.11e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 108          |\n",
      "|    ep_rew_mean          | -6.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1262         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025443821 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0617      |\n",
      "|    explained_variance   | -5.6e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 660          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | 0.0011       |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 124           |\n",
      "|    ep_rew_mean          | 25.7          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1263          |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014453146 |\n",
      "|    clip_fraction        | 0.00742       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0969       |\n",
      "|    explained_variance   | -1.9e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 558           |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.00143      |\n",
      "|    value_loss           | 1.38e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 135         |\n",
      "|    ep_rew_mean          | 55          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1267        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008174002 |\n",
      "|    clip_fraction        | 0.00957     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0613     |\n",
      "|    explained_variance   | -2.35e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.000496   |\n",
      "|    value_loss           | 892         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 147           |\n",
      "|    ep_rew_mean          | 78.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1265          |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035172448 |\n",
      "|    clip_fraction        | 0.00513       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0556       |\n",
      "|    explained_variance   | -7.03e-06     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.00197      |\n",
      "|    value_loss           | 1.59e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 155           |\n",
      "|    ep_rew_mean          | 98.8          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1268          |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017775607 |\n",
      "|    clip_fraction        | 0.00508       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0609       |\n",
      "|    explained_variance   | -4.41e-06     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.2e+03       |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.00168      |\n",
      "|    value_loss           | 1.95e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 161         |\n",
      "|    ep_rew_mean          | 112         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1271        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000183386 |\n",
      "|    clip_fraction        | 0.00352     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0608     |\n",
      "|    explained_variance   | 7.75e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.97e+03    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.000368   |\n",
      "|    value_loss           | 1.98e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 166          |\n",
      "|    ep_rew_mean          | 128          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1270         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035879244 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0645      |\n",
      "|    explained_variance   | 4.95e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 267          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | 0.000963     |\n",
      "|    value_loss           | 1.02e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 170           |\n",
      "|    ep_rew_mean          | 148           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1272          |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 28            |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039025594 |\n",
      "|    clip_fraction        | 0.00698       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.063        |\n",
      "|    explained_variance   | 1.05e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 753           |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.000928     |\n",
      "|    value_loss           | 1.54e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 178          |\n",
      "|    ep_rew_mean          | 161          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1272         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037232516 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0418      |\n",
      "|    explained_variance   | 1.04e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 145          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | 0.00636      |\n",
      "|    value_loss           | 1.43e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 182          |\n",
      "|    ep_rew_mean          | 165          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1273         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034747198 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0338      |\n",
      "|    explained_variance   | 1.99e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 337          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | 0.00404      |\n",
      "|    value_loss           | 923          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 189          |\n",
      "|    ep_rew_mean          | 181          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1270         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011390022 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0366      |\n",
      "|    explained_variance   | 1.67e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 522          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | 0.000391     |\n",
      "|    value_loss           | 916          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 192          |\n",
      "|    ep_rew_mean          | 186          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1272         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011314353 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0424      |\n",
      "|    explained_variance   | 4.27e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 596          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    value_loss           | 1.12e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 197           |\n",
      "|    ep_rew_mean          | 193           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1273          |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 36            |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021524966 |\n",
      "|    clip_fraction        | 0.00327       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0421       |\n",
      "|    explained_variance   | 0.00013       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.53e+03      |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000316     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 198           |\n",
      "|    ep_rew_mean          | 195           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1271          |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 38            |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011182067 |\n",
      "|    clip_fraction        | 0.00322       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0561       |\n",
      "|    explained_variance   | 0.046         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 304           |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.00191      |\n",
      "|    value_loss           | 836           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | 198           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1269          |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 40            |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015831349 |\n",
      "|    clip_fraction        | 0.00366       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0577       |\n",
      "|    explained_variance   | 0.088         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 283           |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.00209      |\n",
      "|    value_loss           | 987           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 202          |\n",
      "|    ep_rew_mean          | 211          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1269         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004309605 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.065       |\n",
      "|    explained_variance   | 0.112        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 457          |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 205          |\n",
      "|    ep_rew_mean          | 224          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1267         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018590773 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0598      |\n",
      "|    explained_variance   | 0.115        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 938          |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    value_loss           | 1.02e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 201          |\n",
      "|    ep_rew_mean          | 220          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1267         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006141296 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0638      |\n",
      "|    explained_variance   | 0.14         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 572          |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | 5.6e-05      |\n",
      "|    value_loss           | 1.23e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 198           |\n",
      "|    ep_rew_mean          | 226           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1267          |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 46            |\n",
      "|    total_timesteps      | 59392         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015155962 |\n",
      "|    clip_fraction        | 0.00283       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0533       |\n",
      "|    explained_variance   | 0.11          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 348           |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.00118      |\n",
      "|    value_loss           | 723           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 195           |\n",
      "|    ep_rew_mean          | 237           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1266          |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 48            |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011572166 |\n",
      "|    clip_fraction        | 0.00264       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0566       |\n",
      "|    explained_variance   | 0.102         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 662           |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.00186      |\n",
      "|    value_loss           | 825           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 189          |\n",
      "|    ep_rew_mean          | 240          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1265         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005092446 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0551      |\n",
      "|    explained_variance   | 0.202        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 401          |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    value_loss           | 895          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 182           |\n",
      "|    ep_rew_mean          | 239           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1265          |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 51            |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016721632 |\n",
      "|    clip_fraction        | 0.00381       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0609       |\n",
      "|    explained_variance   | 0.198         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 400           |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | 6.58e-05      |\n",
      "|    value_loss           | 929           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 174           |\n",
      "|    ep_rew_mean          | 227           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1264          |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 53            |\n",
      "|    total_timesteps      | 67584         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010045315 |\n",
      "|    clip_fraction        | 0.00166       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.06         |\n",
      "|    explained_variance   | 0.199         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 407           |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | 0.000121      |\n",
      "|    value_loss           | 605           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 167          |\n",
      "|    ep_rew_mean          | 211          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1262         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005334667 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0494      |\n",
      "|    explained_variance   | 0.123        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 500          |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    value_loss           | 767          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 162           |\n",
      "|    ep_rew_mean          | 189           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1262          |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 56            |\n",
      "|    total_timesteps      | 71680         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7623925e-05 |\n",
      "|    clip_fraction        | 0.00156       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.054        |\n",
      "|    explained_variance   | 0.196         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 848           |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -0.000115     |\n",
      "|    value_loss           | 836           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 164           |\n",
      "|    ep_rew_mean          | 196           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1261          |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 58            |\n",
      "|    total_timesteps      | 73728         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017815037 |\n",
      "|    clip_fraction        | 0.00381       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0453       |\n",
      "|    explained_variance   | 0.223         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 186           |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | 0.000135      |\n",
      "|    value_loss           | 559           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 165           |\n",
      "|    ep_rew_mean          | 201           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1258          |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 60            |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010731217 |\n",
      "|    clip_fraction        | 0.00249       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0473       |\n",
      "|    explained_variance   | 0.273         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 498           |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | 0.000148      |\n",
      "|    value_loss           | 577           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 166          |\n",
      "|    ep_rew_mean          | 200          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1258         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005584797 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0575      |\n",
      "|    explained_variance   | 0.249        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 412          |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    value_loss           | 640          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 167          |\n",
      "|    ep_rew_mean          | 197          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1258         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015715495 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.049       |\n",
      "|    explained_variance   | 0.171        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 309          |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | 0.000441     |\n",
      "|    value_loss           | 805          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 167           |\n",
      "|    ep_rew_mean          | 193           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1256          |\n",
      "|    iterations           | 40            |\n",
      "|    time_elapsed         | 65            |\n",
      "|    total_timesteps      | 81920         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048387054 |\n",
      "|    clip_fraction        | 0.00503       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0512       |\n",
      "|    explained_variance   | 0.218         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 318           |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.00113      |\n",
      "|    value_loss           | 660           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 166          |\n",
      "|    ep_rew_mean          | 194          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1255         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005725754 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0477      |\n",
      "|    explained_variance   | 0.235        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 308          |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | 0.00117      |\n",
      "|    value_loss           | 646          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 166          |\n",
      "|    ep_rew_mean          | 191          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1255         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009952987 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0538      |\n",
      "|    explained_variance   | 0.206        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 159          |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | 0.000655     |\n",
      "|    value_loss           | 582          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 167           |\n",
      "|    ep_rew_mean          | 202           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1253          |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 70            |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012798086 |\n",
      "|    clip_fraction        | 0.00469       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0471       |\n",
      "|    explained_variance   | 0.272         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 460           |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | 0.000755      |\n",
      "|    value_loss           | 602           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 169          |\n",
      "|    ep_rew_mean          | 210          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1252         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037295665 |\n",
      "|    clip_fraction        | 0.00576      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0518      |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 265          |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | 0.000565     |\n",
      "|    value_loss           | 651          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 169          |\n",
      "|    ep_rew_mean          | 213          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1252         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008396462 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0496      |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 248          |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | 0.000445     |\n",
      "|    value_loss           | 599          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 168          |\n",
      "|    ep_rew_mean          | 214          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1251         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006560979 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0441      |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 312          |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | 0.00366      |\n",
      "|    value_loss           | 844          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 167          |\n",
      "|    ep_rew_mean          | 214          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1251         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016892537 |\n",
      "|    clip_fraction        | 0.00747      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0384      |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 337          |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | 0.00152      |\n",
      "|    value_loss           | 510          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 174         |\n",
      "|    ep_rew_mean          | 220         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1251        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001789998 |\n",
      "|    clip_fraction        | 0.00649     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0344     |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 363         |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.000699    |\n",
      "|    value_loss           | 643         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 176         |\n",
      "|    ep_rew_mean          | 228         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1250        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005105974 |\n",
      "|    clip_fraction        | 0.00347     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0595     |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 364         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    value_loss           | 657         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x20c28e72e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIMESTEPS = 100_000\n",
    "model.learn(total_timesteps=TIMESTEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c95f88",
   "metadata": {},
   "source": [
    "## Print out a visual demonstration of the finally learned policy\n",
    "\n",
    "The goal of this step is to make sure the environment does not simply always selects action 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f018609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to update a dictionary that keeps track of sums and counts for each position in lists\n",
    "def update_position_sums(counter_dict, new_list):\n",
    "    for i, val in enumerate(new_list):\n",
    "        if i not in counter_dict:\n",
    "            counter_dict[i] = [0, 0]  #[sum, count]\n",
    "        counter_dict[i][0] += val\n",
    "        counter_dict[i][1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5a193a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running episodes: 100%|██████████| 1000/1000 [01:15<00:00, 13.33it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"MyEnv-v0\")\n",
    "\n",
    "num_episodes = 1000\n",
    "action_means = {}\n",
    "\n",
    "for ep in tqdm(range(num_episodes), desc=\"Running episodes\"):\n",
    "    obs, _ = env.reset()\n",
    "    actions = []\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        actions.append(action)    # ensure it's 0 or 1\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        if obs[1] > 4000:\n",
    "            print(obs)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    update_position_sums(action_means, actions)\n",
    "\n",
    "# Calculate and print average actions per position\n",
    "average_actions = {pos: sums[0] / sums[1] for pos, sums in action_means.items()}\n",
    "\n",
    "# Sort positions to plot them in order\n",
    "positions = sorted(average_actions.keys())\n",
    "means = [average_actions[pos] for pos in positions]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(positions, means, marker='o', linestyle='-', linewidth=2, markersize=5, color='blue')\n",
    "plt.ylim(0, 1)  # actions are binary, so mean is between 0 and 1\n",
    "plt.xlabel(\"Position in Episode\", fontsize=12)\n",
    "plt.ylim(0,0.001)\n",
    "plt.ylabel(\"Average Action (0–1)\", fontsize=12)\n",
    "plt.title(\"Average Action per Position over 1000 Episodes\", fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Internship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
