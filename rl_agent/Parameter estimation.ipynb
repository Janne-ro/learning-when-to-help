{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28304526",
   "metadata": {},
   "source": [
    "# Parameter Estimation\n",
    "\n",
    "This file is used to estimate the parameters for the BKT model given the observations in the pilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029d24f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b25eef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Dict, Any, Optional\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f539e52",
   "metadata": {},
   "source": [
    "## BKT Model\n",
    "\n",
    "In accordance to Corbett & Anderson (1994) uses Parameters $p_{init}, p_{trans}, p_{slip}$ and $p_{guess}$. So not the classical HMM definition including $B$ (emissions) which would also be unsensical in the current project as forgetting in only nine tasks seems unrealistic.\n",
    "\n",
    "Also includes forward-backward algorithm and Baum-Welch (EM) to fit the model to a student. However, as I later realized using this would potentially be even harmfull as having only nine tasks is too little to meaningfully fit the model.\n",
    "\n",
    "Additionally, conditions slip and guess on task difficulty in accordance to Heffernan et al. (2011):\n",
    "* $P(p_{slip}\\mid task)$\n",
    "* $P(p_{guess}\\mid task)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74a4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for the BKT implementation\n",
    "class BKTModel:\n",
    "\n",
    "    def __init__(self, p_init=0.1, p_trans=0.1, slip=0.1, guess=0.2):\n",
    "        #set parameters\n",
    "        self.p_init = float(p_init)\n",
    "        self.p_trans = float(p_trans)\n",
    "        self.slip = float(slip)\n",
    "        self.guess = float(guess)\n",
    "\n",
    "    #simulate a single student sequence of correctness (0/1)\n",
    "    #outputs a list of 0/1 of given length representing correctness on tasks (does not allow for reattempts here --> logic in multi-skill BKT)\n",
    "    def simulate_student(self, length: int, difficulties = None, seed=None) -> List[int]:\n",
    "\n",
    "        #initate seeds\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        #fill up difficulties if none given (slip and guess is not scaled)\n",
    "        if difficulties == None:\n",
    "            difficulties = [1.0 for _ in range(length)]\n",
    "\n",
    "        #initalize mastery according to p_init    \n",
    "        if random.random() < self.p_init:\n",
    "            L = 1 \n",
    "        else:\n",
    "            L = 0\n",
    "\n",
    "        #initalize the observations of the student \n",
    "        obs = []\n",
    "        for t in range(length):\n",
    "\n",
    "            #get current difficulties and effective slip and guess\n",
    "            difficulty = difficulties[t]\n",
    "            effective_slip = min(max(self.slip * difficulty, 1e-6),1-1e-6)\n",
    "            effective_guess = min(max(self.guess / difficulty, 1e-6),1-1e-6)\n",
    "\n",
    "            #observation for that the student answers correctly on current question\n",
    "            if L == 1:\n",
    "                prob_correct = 1.0 - effective_slip\n",
    "            else:\n",
    "                prob_correct = effective_guess\n",
    "\n",
    "            #sample one observation\n",
    "            if random.random() < prob_correct:\n",
    "                c = 1 \n",
    "            else:\n",
    "                c = 0\n",
    "            obs.append(c)\n",
    "\n",
    "            #do one transition step \n",
    "            if L == 0 and random.random() < self.p_trans:\n",
    "                L = 1\n",
    "\n",
    "            #if L==1, stay learned (implementation without forgetting since to small sequence lengths, only 9)\n",
    "        return obs\n",
    "\n",
    "    #simulate multiple students\n",
    "    def simulate_dataset(self, n_students: int, seq_len: int, seed=None) -> List[List[int]]:\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        return [self.simulate_student(seq_len) for _ in range(n_students)]\n",
    "\n",
    "    #function to compute probability of observation c given latent state L (needed for forward-backward)\n",
    "    #add a dificulty parameter that modifies slip and guess\n",
    "    def _obs_prob(self, c, L, difficulty=1.0, attempt=1):\n",
    "\n",
    "        # scale slip and guess by difficulty (Heffernan et al., 2011)\n",
    "        effective_slip = min(max(self.slip * difficulty, 1e-6), 1-1e-6)\n",
    "        effective_guess = min(max(self.guess / difficulty, 1e-6), 1-1e-6)\n",
    "\n",
    "        #condition slip and guess by attempts\n",
    "        SLIP_GUESS_STEP = 0.1\n",
    "        effective_slip = min(max(effective_slip * (1 - SLIP_GUESS_STEP * (attempt - 1)), 1e-6), 1-1e-6)\n",
    "        effective_guess = min(max(effective_guess * (1 + SLIP_GUESS_STEP * (attempt - 1)), 1e-6), 1-1e-6)\n",
    "\n",
    "        if L == 1:\n",
    "            if c == 1:\n",
    "                return (1.0 - effective_slip) \n",
    "            else:\n",
    "                return effective_slip\n",
    "        else:\n",
    "            if c == 1:\n",
    "                return effective_guess \n",
    "            else:\n",
    "                return 1.0 - effective_guess\n",
    "            \n",
    "    #Forward-backward (EM) algorithm for HMM --> also only needed when fitting parameters given an observation\n",
    "    #compute forward and backward messages and posteriors for one sequence.\n",
    "    #returns alpha, beta, gamma (posterior of L_t=1), xi (expected transitions 0->1 at t)\n",
    "    def forward_backward(self, seq: List[int], difficulties = List[float], repeats = List[int]) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \n",
    "        # set difficulties to 1 if none given\n",
    "        if difficulties is None:\n",
    "            difficulties = [1.0 for _ in range(len(seq))]\n",
    "\n",
    "        #read out the length of the sequence \n",
    "        len_seq = len(seq)\n",
    "\n",
    "        #calculate forward alpha_t(s) = P(C_1..C_t, L_t = s)\n",
    "        alpha = np.zeros((len_seq, 2))\n",
    "        # initalize alpha_0\n",
    "        alpha[0, 1] = self.p_init * self._obs_prob(seq[0], 1, difficulties[0],repeats[0])\n",
    "        alpha[0, 0] = (1 - self.p_init) * self._obs_prob(seq[0], 0, difficulties[0],repeats[0])\n",
    "\n",
    "        # forward pass to calculate alpha_t\n",
    "        for t in range(1, len_seq):\n",
    "            #observation at time t\n",
    "            c = seq[t]\n",
    "            #iterativly apply formula\n",
    "            #if previous was 1, next is 1 (no forgetting)\n",
    "            #P(L_t=1) = alpha[t-1,1]*1 + alpha[t-1,0]*p_trans\n",
    "            alpha[t, 1] = (alpha[t-1,1] * 1.0 + alpha[t-1,0] * self.p_trans) * self._obs_prob(c, 1, difficulties[t],repeats[t])\n",
    "            #P(L_t=0) = only possible from previous 0 and no learn\n",
    "            alpha[t, 0] = (alpha[t-1,0] * (1.0 - self.p_trans)) * self._obs_prob(c, 0, difficulties[t],repeats[t])\n",
    "\n",
    "        #calculate backward beta_t(s) = P(C_t..C_T, L_t = s)\n",
    "        beta = np.zeros((len_seq, 2))\n",
    "        #initalize alpha_T\n",
    "        beta[len_seq-1, :] = 1.0\n",
    "\n",
    "        #backward pass to calculate beta_t\n",
    "        for t in range(len_seq-2, -1, -1):\n",
    "\n",
    "            #observation at time t+1\n",
    "            c_next = seq[t+1]\n",
    "\n",
    "            #iterativly apply formula\n",
    "            #forgetting irrelevant here in backwards\n",
    "            beta[t, 1] = 1.0 * self._obs_prob(c_next, 1, difficulties[t], repeats[t]) * beta[t+1, 1]\n",
    "            #for s=0: s'=1 with p_trans and s'=0 with (1-p_trans)\n",
    "            beta[t, 0] = (self.p_trans * self._obs_prob(c_next, 1, difficulties[t], repeats[t]) * beta[t+1, 1] +\n",
    "                          (1.0 - self.p_trans) * self._obs_prob(c_next, 0, difficulties[t], repeats[t]) * beta[t+1, 0])\n",
    "        \n",
    "        #calculate gamma based on values for alpha and beta (posterior P(L_t = 1 | seq))\n",
    "\n",
    "        #initalize gamma \n",
    "        gamma = np.zeros(len_seq)\n",
    "\n",
    "        #iterate through sequence to calculate gamma_t according to formula \n",
    "        for t in range(len_seq):\n",
    "            denominator = (alpha[t,0] * beta[t,0]) + (alpha[t,1] * beta[t,1])\n",
    "            #check if denominator is zero to avoid division by zero\n",
    "            if denominator == 0:\n",
    "                gamma[t] = 0.0\n",
    "            else:\n",
    "                gamma[t] = (alpha[t,1] * beta[t,1]) / denominator\n",
    "\n",
    "        # calculate xi: expected nr of transitions from 0->1 at time t (i.e., from L_t=0 to L_{t+1}=1)\n",
    "        # sum_j xi(i,j) = gamma(i)\n",
    "        #initalize xi\n",
    "        xi = np.zeros(len_seq-1)\n",
    "\n",
    "        #iterate through sequence to calculate xi_t according to formula\n",
    "        for t in range(len_seq-1):\n",
    "\n",
    "            #observation at time t+1\n",
    "            c_next = seq[t+1]\n",
    "\n",
    "            #according to forward-backward formula:\n",
    "            # joint prob proportional to alpha[t,0] * P(L_{t+1}=1|L_t=0)=p_trans * P(C_{t+1}|1) * beta[t+1,1]\n",
    "            nominator = alpha[t,0] * self.p_trans * self._obs_prob(c_next, 1, difficulties[t], repeats[t]) * beta[t+1,1]\n",
    "            #compute sum over s,s' of alpha[t,s]*P(s->s')*P(obs_{t+1}|s')*beta[t+1,s']\n",
    "            denominator = (\n",
    "                alpha[t,0] * ( (1.0-self.p_trans) * self._obs_prob(c_next, 0, difficulties[t], repeats[t]) * beta[t+1,0]\n",
    "                              + self.p_trans * self._obs_prob(c_next, 1, difficulties[t], repeats[t]) * beta[t+1,1] )\n",
    "                + alpha[t,1] * (1.0 * self._obs_prob(c_next, 1, difficulties[t], repeats[t]) * beta[t+1,1])\n",
    "            )\n",
    "\n",
    "            #check if denominator is zero to avoid division by zero\n",
    "            if denominator == 0:\n",
    "                xi[t] = 0.0\n",
    "            else:\n",
    "                xi[t] = nominator / denominator\n",
    "\n",
    "        #return all computed values (only gamma and xi needed for Baum-Welch EM)\n",
    "        return alpha, beta, gamma, xi\n",
    "\n",
    "    #helper function to return how many attempts were used for each task\n",
    "    def get_attempts(self, data):\n",
    "        counters = defaultdict(int)  #keeps track of how many times we've seen each task_id\n",
    "        attempts = []\n",
    "        \n",
    "        for correct, task_id in data:\n",
    "            counters[task_id] += 1      #increment count for this task\n",
    "            attempts.append(counters[task_id])\n",
    "        \n",
    "        return attempts\n",
    "    \n",
    "    #Fit parameters with EM (Baum-Welch) using multiple sequences (list of lists of 0/1) \n",
    "    def fit(self, sequences: List[List[Tuple[int,float]]], difficulties: List[float], n_iters=15, telling=False):\n",
    "        for it in range(n_iters):\n",
    "            #initalize variables to accumulate expected counts\n",
    "            sum_gamma0 = 0.0   # expected times in state 0\n",
    "            sum_gamma1 = 0.0   #expected times in state 1\n",
    "            sum_init1 = 0.0  #expected initial state 1\n",
    "            sum_trans_0_to_1 = 0.0  #expected transitions 0->1\n",
    "            sum_correct_in_state1 = 0.0 #expected correct responses in state 1\n",
    "            sum_state1 = 0.0  #expected times in state 1\n",
    "            sum_correct_in_state0 = 0.0  #expected correct responses in state 0\n",
    "            sum_state0 = 0.0  # expected times in state 0\n",
    "\n",
    "            #E-step: compute expected counts\n",
    "            #iterate through all sequences\n",
    "            for i, sequence in enumerate(sequences):\n",
    "\n",
    "                #get the correct results and task difficulties\n",
    "                seq = [\n",
    "                    x for (x, _) in sequence\n",
    "                ]\n",
    "\n",
    "                seq_difficulties = [\n",
    "                    difficulties[y] for (_, y) in sequence\n",
    "                ]\n",
    "\n",
    "                seq_repeats = self.get_attempts(sequence)\n",
    "\n",
    "\n",
    "                #ignore if sequence length is zero\n",
    "                if len(seq) == 0:\n",
    "                    continue\n",
    "\n",
    "                #get results from forward-backward and update sums\n",
    "                alpha, beta, gamma, xi = self.forward_backward(seq, seq_difficulties, seq_repeats)\n",
    "                \n",
    "                len_seq = len(seq)\n",
    "                sum_init1 += gamma[0]\n",
    "                sum_gamma1 += gamma.sum()\n",
    "                sum_gamma0 += (len_seq - gamma.sum())\n",
    "                sum_trans_0_to_1 += xi.sum() #expected transitions\n",
    "                #expected observation counts\n",
    "                #for state1: expected number of times in state1 and response correct\n",
    "\n",
    "                #iterate through current sequence \n",
    "                for t, c in enumerate(seq):\n",
    "\n",
    "                    #update sums according to gamma_t (formulas for expected counts)\n",
    "                    if gamma[t] > 0:\n",
    "                        if c == 1:\n",
    "                            sum_correct_in_state1 += gamma[t]\n",
    "                        sum_state1 += gamma[t]\n",
    "                        sum_state0 += (1.0 - gamma[t])\n",
    "                        if c == 1:\n",
    "                            sum_correct_in_state0 += (1.0 - gamma[t])\n",
    "                    else:\n",
    "                        # gamma[t]==0 --> contribution to state0 only\n",
    "                        sum_state0 += 1.0\n",
    "                        if c == 1:\n",
    "                            sum_correct_in_state0 += 1.0\n",
    "\n",
    "            #restirict to prevent extreme local maxima (espesically for skill 1)\n",
    "            p_init_min, p_init_max = 0.05, 0.95\n",
    "            slip_min, slip_max = 0.01, 0.35\n",
    "            guess_min, guess_max = 0.01, 0.35\n",
    "            p_trans_min, p_trans_max = 0.01, 0.5 \n",
    "\n",
    "\n",
    "            #M-step updates according to formulas \n",
    "            new_p_init = (sum_init1 / len(sequences)) if len(sequences) > 0 else self.p_init\n",
    "            new_p_trans = (sum_trans_0_to_1 / max(1e-8, sum_gamma0))  # expected transitions / expected times in 0\n",
    "            new_slip = 1.0 - (sum_correct_in_state1 / max(1e-8, sum_state1))\n",
    "            new_guess = (sum_correct_in_state0 / max(1e-8, sum_state0))\n",
    "            # clip to avoid degenerate values\n",
    "            self.p_init = float(min(max(new_p_init, p_init_min), p_init_max))\n",
    "            self.p_trans = float(min(max(new_p_trans, p_trans_min), p_trans_max))\n",
    "            self.slip   = float(min(max(new_slip, slip_min), slip_max))\n",
    "            self.guess  = float(min(max(new_guess, guess_min), guess_max))\n",
    "\n",
    "            #if telling print out the current vaues of the parameters\n",
    "            if telling:\n",
    "                print(f\"EM iter {it+1}: p_init={self.p_init:.5f}, p_trans={self.p_trans:.5f}, slip={self.slip:.5f}, guess={self.guess:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8354d632",
   "metadata": {},
   "source": [
    "## Multi Skill BKT Model\n",
    "\n",
    "This is a extension to the previously defined simple BKT model that allows that multiple skills are needed for one task. It does so by multplying slip and guess chance conditioned on mastery for both skills (common practice). Additionally, it includes the following extensions to the vanilla BKT model:\n",
    "1. Incoperates difficulties by conditioning slip and guess on difficulty (Heffernan et al., 2011):\n",
    "* $P(p_{slip}\\mid task)$\n",
    "* $P(p_{guess}\\mid task)$\n",
    "2. Allows for multiple attempts after inital failure and conditions slip, guess and transition probabilite on this (Bhatt et al., 2020):\n",
    "* $P(p_{slip}\\mid \\# attempt)$\n",
    "* $P(p_{guess}\\mid \\# attempt)$\n",
    "* $P(p_{trans}\\mid \\# attempt)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2408cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for the BKT implementation which allows having multiple skills requrired in one task\n",
    "#includes:\n",
    "#   imediate retakes until correct or probabilistic retakes that condition slip, guess and transition probabilities\n",
    "#   task difficulties that condition slip and guess\n",
    "class MultiSkillBKT:\n",
    "\n",
    "    #initalize with n_skills BKT models\n",
    "    def __init__(self, n_skills: int, p_init=0.1, p_trans=0.1, slip=0.1, guess=0.2):\n",
    "        # Create one BKTModel per skill\n",
    "        self.skills = [BKTModel(p_init, p_trans, slip, guess) for _ in range(n_skills)]\n",
    "        self.n_skills = n_skills\n",
    "\n",
    "    \n",
    "    # Simulate a student sequence of responses for tasks, allowing retakes.\n",
    "    # Parameters:\n",
    "    #   - task_skill_map: List of tasks, each task is a list of skill indices needed for the task\n",
    "    #   - seed: random seed for reproducibility\n",
    "    #   - task_difficulties: Optional list of task difficulties (float) for each task\n",
    "    #   - retake_until_correct: if True, retry wrong attempts until correct or max_retries reached.\n",
    "    #   - max_retries: maximum number of attempts per task (including first attempt).\n",
    "\n",
    "    #returns a dictionary with keys:\n",
    "    #   - 'task' : index in task_skill_map\n",
    "    #   - 'attempt' : attempt number for that task (1,2,...) \n",
    "    #   - 'skills' : list of skill indices required for that task\n",
    "    #   - 'correct' : 0/1 whether the student answered correctly on that attempt\n",
    "    #   - 'difficulty' : difficulty of that task\n",
    "    def simulate_student(self, task_skill_map, seed = None, *, task_difficulties = None, retake_until_correct = False, max_retries = None):\n",
    "        \n",
    "        #set seed if given\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "\n",
    "        #set task difficulties to 1 if none given\n",
    "        if task_difficulties is None:\n",
    "            task_difficulties = [1.0 for _ in range(len(task_skill_map))]\n",
    "\n",
    "        # initialize per-skill mastery state based on p_init\n",
    "        L = [1 if random.random() < sk.p_init else 0 for sk in self.skills]\n",
    "        records: List[Dict[str, Any]] = []\n",
    "\n",
    "        for task_idx, skills_required in enumerate(task_skill_map):\n",
    "            attempt = 0\n",
    "            while True:\n",
    "                attempt += 1\n",
    "\n",
    "                # compute probability correct on this attempt (independent slip/guess per skill)\n",
    "                prob_correct = 1.0 \n",
    "\n",
    "                for s in skills_required:\n",
    "                    \n",
    "                    #condition slip and guess by difficulty\n",
    "                    effective_slip = min(max(self.skills[s].slip * task_difficulties[task_idx], 1e-6),1-1e-6)\n",
    "                    effective_guess = min(max(self.skills[s].guess / task_difficulties[task_idx], 1e-6),1-1e-6)\n",
    "\n",
    "                    #condition slip and guess by attempts \n",
    "                    SLIP_GUESS_STEP = 0.1\n",
    "                    effective_slip = min(max(effective_slip * (1 - SLIP_GUESS_STEP * (attempt - 1)), 1e-6), 1-1e-6)\n",
    "                    effective_guess = min(max(effective_guess * (1 + SLIP_GUESS_STEP * (attempt - 1)), 1e-6), 1-1e-6)\n",
    "\n",
    "                    #caluclate prob_correct contribution for that skill\n",
    "                    if L[s] == 1:\n",
    "                        prob_correct *= (1.0 - effective_slip)\n",
    "                    else:\n",
    "                        prob_correct *= effective_guess\n",
    "\n",
    "                #sample correctness for this attempt\n",
    "                if random.random() < prob_correct:\n",
    "                    c=1\n",
    "                else:\n",
    "                    c=0\n",
    "\n",
    "                #append current attempt record\n",
    "                records.append({\n",
    "                    'task': task_idx,\n",
    "                    'attempt': attempt,\n",
    "                    'skills': list(skills_required),\n",
    "                    'correct': c,\n",
    "                    'difficulty': task_difficulties[task_idx]\n",
    "                })\n",
    "\n",
    "                #after each attempt, update mastery for each skill (no forgetting)\n",
    "                for s in skills_required:\n",
    "\n",
    "                    P_TRANS_STEP = 0.1\n",
    "\n",
    "                    #condition p_trans on attempts\n",
    "                    effective_p_trans = min(self.skills[s].p_trans * (1 + P_TRANS_STEP * (attempt - 1)), 1 - 1e-6)\n",
    "\n",
    "                    if L[s] == 0 and random.random() < effective_p_trans:\n",
    "                        L[s] = 1\n",
    "\n",
    "                #decide whether to retry\n",
    "                if c == 1:\n",
    "                    break  #correct --> stop retrying (common policy)\n",
    "                # if incorrect retry until correct or max_retries reached \n",
    "                if retake_until_correct:\n",
    "                    if max_retries is None:\n",
    "                        continue\n",
    "                    elif attempt >= max_retries:\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    # no retakes if set to false\n",
    "                    break\n",
    "\n",
    "        return records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb6ede",
   "metadata": {},
   "source": [
    "## Example simulation\n",
    "\n",
    "Defines a task skill mapping and difficulties for each task. Afterwards initalizes a multi skill BKT and simulates a students behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0429e0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task 0, attempt 1, skills [0], difficulty=1, correct=1\n",
      "task 1, attempt 1, skills [1], difficulty=1.1, correct=0\n",
      "task 1, attempt 2, skills [1], difficulty=1.1, correct=0\n",
      "task 1, attempt 3, skills [1], difficulty=1.1, correct=0\n",
      "task 1, attempt 4, skills [1], difficulty=1.1, correct=1\n",
      "task 2, attempt 1, skills [0, 1], difficulty=0.8, correct=1\n",
      "task 3, attempt 1, skills [0], difficulty=0.7, correct=1\n",
      "task 4, attempt 1, skills [1], difficulty=0.7, correct=1\n",
      "task 5, attempt 1, skills [0, 1], difficulty=0.6, correct=1\n",
      "task 6, attempt 1, skills [0], difficulty=1, correct=1\n",
      "task 7, attempt 1, skills [1], difficulty=1.3, correct=1\n",
      "task 8, attempt 1, skills [0, 1], difficulty=0.6, correct=1\n"
     ]
    }
   ],
   "source": [
    "#Example task mapping\n",
    "task_skill_map = [[0], [1], [0,1], [0], [1], [0,1], [0], [1], [0,1]]\n",
    "difficulties = [1, 1.1, 0.8, 0.7, 0.7, 0.6, 1, 1.3, 0.6]\n",
    "\n",
    "#initialize multi-skill BKT\n",
    "ms_bkt = MultiSkillBKT(n_skills=2, p_init=0.1, p_trans=0.1, slip=0.1, guess=0.2)\n",
    "\n",
    "# Example: retry until correct, up to 4 attempts\n",
    "records = ms_bkt.simulate_student(task_skill_map, task_difficulties=difficulties, seed=43, retake_until_correct=True)\n",
    "\n",
    "#output results \n",
    "for r in records:\n",
    "    print(f\"task {r['task']}, attempt {r['attempt']}, skills {r['skills']}, difficulty={r['difficulty']}, correct={r['correct']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "860adfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_sequences = [\n",
    "        [(0,0),(0,0),(0,0),(1,0),(0,1),(0,1),(1,1),(1,2),(0,3),(1,3),(0,4),(1,4),(0,5),(1,5),(0,6),(0,6),(1,6),(0,7),(0,7),(0,7),(0,7),(0,7),(0,7),(0,7),(0,7),(0,7),(1,7),(1,8)], # first participant; well at least first in excel\n",
    "        [(0,0),(1,0),(1,1),(1,2),(0,3),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8)], #second participant\n",
    "        [(0,0),(1,0),(1,1),(0,2),(1,2),(1,3),(1,4),(0,5),(1,5),(0,6),(0,6),(0,6),(1,6),(0,7),(0,7),(0,7),(0,7),(0,7),(1,7),(1,8)], #third participant\n",
    "        [(0,0),(1,0),(1,1),(1,2),(0,3),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8)], #fourth participant\n",
    "        [(1,0),(1,1),(1,2),(0,3),(1,3),(1,4),(1,5),(1,6),(0,7),(1,7),(1,8)], #fifth participant \n",
    "        [(0,0),(0,0),(0,0),(1,0),(1,1),(1,2),(1,3),(1,4),(0,5),(1,5),(1,6),(1,7),(1,8)], #sixth participant\n",
    "        [(1,0),(1,1),(1,2),(1,3),(1,4),(0,5),(0,5),(0,5),(0,5),(0,5),(1,5),(1,6),(1,7),(1,8)], #seventh participant\n",
    "        [(0,0),(0,0),(0,0),(0,0),(0,0),(1,0),(0,1),(0,1),(1,1),(0,2),(0,2),(1,2),(0,3),(0,3),(0,3),(0,3),(0,3),(0,3),(0,3),(0,3),(0,3),(0,3),(1,3),(1,4),(0,5),(1,5),(0,6),(1,6),(0,7),(0,7),(0,7),(0,7),(0,7),(0,7),(0,7),(1,7),(1,8)], #eight participant\n",
    "        [(1,0),(1,1),(1,2),(0,3),(0,3),(1,3),(1,4),(1,5),(1,6),(0,7),(1,7),(1,8)] #ninth participant\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4978632c",
   "metadata": {},
   "source": [
    "## Get BKT parameters\n",
    "\n",
    "Use the data collected in the first pilot to get the most likely BKT parameters \n",
    "\n",
    "We have to take care of the following two issues: \n",
    "1) We can have multiple attempts on the same task --> we can just have them treat the repeated attempt as new task (does not violate any assumtion)\n",
    "2) We assume for fitting parameters that each task is equally hard\n",
    "3) We treat each skill as seperate since in the given setup [0,1], [0,1], [0,1],[0,2], [0,2], [0,2],[0,3], [0,3], [0,3] all skills are conditionally independent of each other with exception of 0 which will be better estimated since it has more observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636b24fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 1), (1, 1), (1, 2)], [(0, 0), (1, 0), (1, 1), (1, 2)], [(0, 0), (1, 0), (1, 1), (0, 2), (1, 2)], [(0, 0), (1, 0), (1, 1), (1, 2)], [(1, 0), (1, 1), (1, 2)], [(0, 0), (0, 0), (0, 0), (1, 0), (1, 1), (1, 2)], [(1, 0), (1, 1), (1, 2)], [(0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 1), (1, 1), (0, 2), (0, 2), (1, 2)], [(1, 0), (1, 1), (1, 2)]]\n",
      "[[(0, 3), (1, 3), (0, 4), (1, 4), (0, 5), (1, 5)], [(0, 3), (1, 3), (1, 4), (1, 5)], [(1, 3), (1, 4), (0, 5), (1, 5)], [(0, 3), (1, 3), (1, 4), (1, 5)], [(0, 3), (1, 3), (1, 4), (1, 5)], [(1, 3), (1, 4), (0, 5), (1, 5)], [(1, 3), (1, 4), (0, 5), (0, 5), (0, 5), (0, 5), (0, 5), (1, 5)], [(0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (1, 3), (1, 4), (0, 5), (1, 5)], [(0, 3), (0, 3), (1, 3), (1, 4), (1, 5)]]\n",
      "[[(0, 6), (0, 6), (1, 6), (0, 7), (0, 7), (0, 7), (0, 7), (0, 7), (0, 7), (0, 7), (0, 7), (0, 7), (1, 7), (1, 8)], [(1, 6), (1, 7), (1, 8)], [(0, 6), (0, 6), (0, 6), (1, 6), (0, 7), (0, 7), (0, 7), (0, 7), (0, 7), (1, 7), (1, 8)], [(1, 6), (1, 7), (1, 8)], [(1, 6), (0, 7), (1, 7), (1, 8)], [(1, 6), (1, 7), (1, 8)], [(1, 6), (1, 7), (1, 8)], [(0, 6), (1, 6), (0, 7), (0, 7), (0, 7), (0, 7), (0, 7), (0, 7), (0, 7), (1, 7), (1, 8)], [(1, 6), (0, 7), (1, 7), (1, 8)]]\n",
      "Most likely parameters (local maxima): \n",
      "Skill 0: p_init=0.351, p_trans=0.192, slip=0.066, guess=0.240\n",
      "Skill 1: p_init=0.050, p_trans=0.082, slip=0.048, guess=0.350\n",
      "Skill 2: p_init=0.645, p_trans=0.051, slip=0.088, guess=0.198\n"
     ]
    }
   ],
   "source": [
    "#setup learning sequence in the form [(0,0),(correct?,subtask(1-9))]  --> the requried skill can be infered from the subtask\n",
    "learning_sequences = [\n",
    "        [(0,0),(0,0),(0,0),(1,0),(0,1),(0,1),(1,1),(1,2),(0,3),(1,3),(0,4),(1,4),(0,5),(1,5),(0,6),(0,6),(1,6),(0,7),(0,7),(0,7),(0,7),(0,7),(0,7),(0,7),(0,7),(0,7),(1,7),(1,8)], # first participant; well at least first in excel\n",
    "        [(0,0),(1,0),(1,1),(1,2),(0,3),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8)], #second participant\n",
    "        [(0,0),(1,0),(1,1),(0,2),(1,2),(1,3),(1,4),(0,5),(1,5),(0,6),(0,6),(0,6),(1,6),(0,7),(0,7),(0,7),(0,7),(0,7),(1,7),(1,8)], #third participant\n",
    "        [(0,0),(1,0),(1,1),(1,2),(0,3),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8)], #fourth participant\n",
    "        [(1,0),(1,1),(1,2),(0,3),(1,3),(1,4),(1,5),(1,6),(0,7),(1,7),(1,8)], #fifth participant \n",
    "        [(0,0),(0,0),(0,0),(1,0),(1,1),(1,2),(1,3),(1,4),(0,5),(1,5),(1,6),(1,7),(1,8)], #sixth participant\n",
    "        [(1,0),(1,1),(1,2),(1,3),(1,4),(0,5),(0,5),(0,5),(0,5),(0,5),(1,5),(1,6),(1,7),(1,8)], #seventh participant\n",
    "        [(0,0),(0,0),(0,0),(0,0),(0,0),(1,0),(0,1),(0,1),(1,1),(0,2),(0,2),(1,2),(0,3),(0,3),(0,3),(0,3),(0,3),(0,3),(0,3),(0,3),(0,3),(0,3),(1,3),(1,4),(0,5),(1,5),(0,6),(1,6),(0,7),(0,7),(0,7),(0,7),(0,7),(0,7),(0,7),(1,7),(1,8)], #eight participant\n",
    "        [(1,0),(1,1),(1,2),(0,3),(0,3),(1,3),(1,4),(1,5),(1,6),(0,7),(1,7),(1,8)] #ninth participant\n",
    "    ]\n",
    "\n",
    "#holds the difficultie as informed by pilots --> index is here equal to subtask \n",
    "difficulties = [1.1, 1.2, 0.9, 0.9, 0.9, 0.8, 1.1, 1.3, 0.7]\n",
    "\n",
    "\n",
    "#fits one BKT model per skill using per-student attempt sequences\n",
    "def fit_bkt_per_skill(\n",
    "    learning_sequences: List[Tuple[int, int]],\n",
    "    n_skills: int,\n",
    "    difficulties: List[int] = None,\n",
    "    *,\n",
    "    n_iters: int = 20,\n",
    "    p_init=0.05,\n",
    "    p_trans=0.1,\n",
    "    slip=0.1,\n",
    "    guess=0.2\n",
    "):\n",
    "\n",
    "    #1. Build per-skill, per-student sequences\n",
    "    #skill_sequences[s] = list of student sequences for skill s\n",
    "    skill_sequences = [[] for _ in range(n_skills)]\n",
    "\n",
    "    for student_seq in learning_sequences:\n",
    "        #initialize empty sequence for this student for each skill\n",
    "        student_skill_seqs = [[] for _ in range(n_skills)]\n",
    "\n",
    "        for correct, subtask in student_seq:\n",
    "            if 0<=subtask<=2:\n",
    "                skill = 0\n",
    "            elif 3<=subtask<=5:\n",
    "                skill = 1\n",
    "            elif 6<=subtask<=8:\n",
    "                skill = 2\n",
    "            else:\n",
    "                raise RuntimeWarning()\n",
    "            student_skill_seqs[skill].append((correct,subtask))\n",
    "\n",
    "        #append non-empty sequences to global skill list\n",
    "        for s in range(n_skills):\n",
    "            if student_skill_seqs[s]:\n",
    "                skill_sequences[s].append(student_skill_seqs[s])\n",
    "\n",
    "    #2. Fit one BKT per skill using EM \n",
    "    skill_models = []\n",
    "    for s in range(n_skills):\n",
    "\n",
    "        #intialize model\n",
    "        model = BKTModel(p_init=p_init, p_trans=p_trans, slip=slip, guess=guess)\n",
    "\n",
    "        print(skill_sequences[s])\n",
    "\n",
    "        model.fit(skill_sequences[s], difficulties=difficulties, n_iters=n_iters)\n",
    "        skill_models.append(model)\n",
    "\n",
    "    return skill_models\n",
    "\n",
    "#return the fitted bkt models\n",
    "models = fit_bkt_per_skill(\n",
    "    learning_sequences,\n",
    "    difficulties=difficulties,\n",
    "    n_skills=3,\n",
    "    n_iters=25\n",
    ")\n",
    "\n",
    "#take into account that skill 0 was not used in the end as it was decided to assume one skill is used per task\n",
    "print(\"Most likely parameters (local maxima): \")\n",
    "for i, m in enumerate(models):\n",
    "    print(\n",
    "        f\"Skill {i}: \"\n",
    "        f\"p_init={m.p_init:.3f}, \"\n",
    "        f\"p_trans={m.p_trans:.3f}, \"\n",
    "        f\"slip={m.slip:.3f}, \"\n",
    "        f\"guess={m.guess:.3f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Internship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
