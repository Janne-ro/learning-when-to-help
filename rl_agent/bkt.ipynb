{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a029d24f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b25eef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Dict, Any, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f539e52",
   "metadata": {},
   "source": [
    "## BKT Model\n",
    "\n",
    "In accordance to Corbett & Anderson (1994) uses Parameters $p_{init}, p_{trans}, p_{slip}$ and $p_{guess}$. So not the classical HMM definition including $B$ (emissions) which would also be unsensical in the current project as forgetting in only nine tasks seems unrealistic.\n",
    "\n",
    "Also includes forward-backward algorithm and Baum-Welch (EM) to fit the model to a student. However, as I later realized using this would potentially be even harmfull as having only nine tasks is too little to meaningfully fit the model.\n",
    "\n",
    "Additionally, conditions slip and guess on task difficulty in accordance to Heffernan et al. (2011):\n",
    "* $P(p_{slip}\\mid task)$\n",
    "* $P(p_{guess}\\mid task)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a74a4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for the BKT implementation\n",
    "class BKTModel:\n",
    "\n",
    "    def __init__(self, p_init=0.1, p_trans=0.1, slip=0.1, guess=0.2):\n",
    "        #set parameters\n",
    "        self.p_init = float(p_init)\n",
    "        self.p_trans = float(p_trans)\n",
    "        self.slip = float(slip)\n",
    "        self.guess = float(guess)\n",
    "\n",
    "    #simulate a single student sequence of correctness (0/1)\n",
    "    #outputs a list of 0/1 of given length representing correctness on tasks (does not allow for reattempts here --> logic in multi-skill BKT)\n",
    "    def simulate_student(self, length: int, difficulties = None, seed=None) -> List[int]:\n",
    "\n",
    "        #initate seeds\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        #fill up difficulties if none given (slip and guess is not scaled)\n",
    "        if difficulties == None:\n",
    "            difficulties = [1.0 for _ in range(length)]\n",
    "\n",
    "        #initalize mastery according to p_init    \n",
    "        if random.random() < self.p_init:\n",
    "            L = 1 \n",
    "        else:\n",
    "            L = 0\n",
    "\n",
    "        #initalize the observations of the student \n",
    "        obs = []\n",
    "        for t in range(length):\n",
    "\n",
    "            #get current difficulties and effective slip and guess\n",
    "            difficulty = difficulties[t]\n",
    "            effective_slip = min(max(self.slip * difficulty, 1e-6),1-1e-6)\n",
    "            effective_guess = min(max(self.guess / difficulty, 1e-6),1-1e-6)\n",
    "\n",
    "            #observation for that the student answers correctly on current question\n",
    "            if L == 1:\n",
    "                prob_correct = 1.0 - effective_slip\n",
    "            else:\n",
    "                prob_correct = effective_guess\n",
    "\n",
    "            #sample one observation\n",
    "            if random.random() < prob_correct:\n",
    "                c = 1 \n",
    "            else:\n",
    "                c = 0\n",
    "            obs.append(c)\n",
    "\n",
    "            #do one transition step \n",
    "            if L == 0 and random.random() < self.p_trans:\n",
    "                L = 1\n",
    "\n",
    "            #if L==1, stay learned (implementation without forgetting since to small sequence lengths, only 9)\n",
    "        return obs\n",
    "\n",
    "    #simulate multiple students\n",
    "    def simulate_dataset(self, n_students: int, seq_len: int, seed=None) -> List[List[int]]:\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        return [self.simulate_student(seq_len) for _ in range(n_students)]\n",
    "\n",
    "    #function to compute probability of observation c given latent state L (needed for forward-backward)\n",
    "    #add a dificulty parameter that modifies slip and guess\n",
    "    def _obs_prob(self, c, L, difficulty=1.0):\n",
    "\n",
    "        # scale slip and guess by difficulty (Heffernan et al., 2011)\n",
    "        effective_slip = min(max(self.slip * difficulty, 1e-6), 1-1e-6)\n",
    "        effective_guess = min(max(self.guess / difficulty, 1e-6), 1-1e-6)\n",
    "\n",
    "        if L == 1:\n",
    "            if c == 1:\n",
    "                return (1.0 - effective_slip) \n",
    "            else:\n",
    "                return effective_slip\n",
    "        else:\n",
    "            if c == 1:\n",
    "                return effective_guess \n",
    "            else:\n",
    "                return 1.0 - effective_guess\n",
    "            \n",
    "    #Forward-backward (EM) algorithm for HMM --> also only needed when fitting parameters given an observation\n",
    "    #compute forward and backward messages and posteriors for one sequence.\n",
    "    #returns alpha, beta, gamma (posterior of L_t=1), xi (expected transitions 0->1 at t)\n",
    "    def forward_backward(self, seq: List[int], difficulties: List[float] = None) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \n",
    "        # set difficulties to 1 if none given\n",
    "        if difficulties is None:\n",
    "            difficulties = [1.0 for _ in range(len(seq))]\n",
    "\n",
    "        #read out the length of the sequence \n",
    "        len_seq = len(seq)\n",
    "\n",
    "        #calculate forward alpha_t(s) = P(C_1..C_t, L_t = s)\n",
    "        alpha = np.zeros((len_seq, 2))\n",
    "        # initalize alpha_0\n",
    "        alpha[0, 1] = self.p_init * self._obs_prob(seq[0], 1, difficulties[0])\n",
    "        alpha[0, 0] = (1 - self.p_init) * self._obs_prob(seq[0], 0, difficulties[0])\n",
    "\n",
    "        # forward pass to calculate alpha_t\n",
    "        for t in range(1, len_seq):\n",
    "            #observation at time t\n",
    "            c = seq[t]\n",
    "            #iterativly apply formula\n",
    "            #if previous was 1, next is 1 (no forgetting)\n",
    "            #P(L_t=1) = alpha[t-1,1]*1 + alpha[t-1,0]*p_trans\n",
    "            alpha[t, 1] = (alpha[t-1,1] * 1.0 + alpha[t-1,0] * self.p_trans) * self._obs_prob(c, 1, difficulties[t])\n",
    "            #P(L_t=0) = only possible from previous 0 and no learn\n",
    "            alpha[t, 0] = (alpha[t-1,0] * (1.0 - self.p_trans)) * self._obs_prob(c, 0, difficulties[t])\n",
    "\n",
    "        #calculate backward beta_t(s) = P(C_t..C_T, L_t = s)\n",
    "        beta = np.zeros((len_seq, 2))\n",
    "        #initalize alpha_T\n",
    "        beta[len_seq-1, :] = 1.0\n",
    "\n",
    "        #backward pass to calculate beta_t\n",
    "        for t in range(len_seq-2, -1, -1):\n",
    "\n",
    "            #observation at time t+1\n",
    "            c_next = seq[t+1]\n",
    "\n",
    "            #iterativly apply formula\n",
    "            #forgetting irrelevant here in backwards\n",
    "            beta[t, 1] = 1.0 * self._obs_prob(c_next, 1, difficulties[t]) * beta[t+1, 1]\n",
    "            #for s=0: s'=1 with p_trans and s'=0 with (1-p_trans)\n",
    "            beta[t, 0] = (self.p_trans * self._obs_prob(c_next, 1, difficulties[t]) * beta[t+1, 1] +\n",
    "                          (1.0 - self.p_trans) * self._obs_prob(c_next, 0, difficulties[t]) * beta[t+1, 0])\n",
    "        \n",
    "        #calculate gamma based on values for alpha and beta (posterior P(L_t = 1 | seq))\n",
    "\n",
    "        #initalize gamma \n",
    "        gamma = np.zeros(len_seq)\n",
    "\n",
    "        #iterate through sequence to calculate gamma_t according to formula \n",
    "        for t in range(len_seq):\n",
    "            denominator = (alpha[t,0] * beta[t,0]) + (alpha[t,1] * beta[t,1])\n",
    "            #check if denominator is zero to avoid division by zero\n",
    "            if denominator == 0:\n",
    "                gamma[t] = 0.0\n",
    "            else:\n",
    "                gamma[t] = (alpha[t,1] * beta[t,1]) / denominator\n",
    "\n",
    "        # calculate xi: expected nr of transitions from 0->1 at time t (i.e., from L_t=0 to L_{t+1}=1)\n",
    "        # sum_j xi(i,j) = gamma(i)\n",
    "        #initalize xi\n",
    "        xi = np.zeros(len_seq-1)\n",
    "\n",
    "        #iterate through sequence to calculate xi_t according to formula\n",
    "        for t in range(len_seq-1):\n",
    "\n",
    "            #observation at time t+1\n",
    "            c_next = seq[t+1]\n",
    "\n",
    "            #according to forward-backward formula:\n",
    "            # joint prob proportional to alpha[t,0] * P(L_{t+1}=1|L_t=0)=p_trans * P(C_{t+1}|1) * beta[t+1,1]\n",
    "            nominator = alpha[t,0] * self.p_trans * self._obs_prob(c_next, 1, difficulties[t]) * beta[t+1,1]\n",
    "            #compute sum over s,s' of alpha[t,s]*P(s->s')*P(obs_{t+1}|s')*beta[t+1,s']\n",
    "            denominator = (\n",
    "                alpha[t,0] * ( (1.0-self.p_trans) * self._obs_prob(c_next, 0, difficulties[t]) * beta[t+1,0]\n",
    "                              + self.p_trans * self._obs_prob(c_next, 1, difficulties[t]) * beta[t+1,1] )\n",
    "                + alpha[t,1] * (1.0 * self._obs_prob(c_next, 1, difficulties[t]) * beta[t+1,1])\n",
    "            )\n",
    "\n",
    "            #check if denominator is zero to avoid division by zero\n",
    "            if denominator == 0:\n",
    "                xi[t] = 0.0\n",
    "            else:\n",
    "                xi[t] = nominator / denominator\n",
    "\n",
    "        #return all computed values (only gamma and xi needed for Baum-Welch EM)\n",
    "        return alpha, beta, gamma, xi\n",
    "\n",
    "    #Fit parameters with EM (Baum-Welch) using multiple sequences (list of lists of 0/1) --> acutally unneded as we do not have student data here\n",
    "    def fit(self, sequences: List[List[int]], n_iters=15, telling=False):\n",
    "        for it in range(n_iters):\n",
    "            #initalize variables to accumulate expected counts\n",
    "            sum_gamma0 = 0.0   # expected times in state 0\n",
    "            sum_gamma1 = 0.0   #expected times in state 1\n",
    "            sum_init1 = 0.0  #expected initial state 1\n",
    "            sum_trans_0_to_1 = 0.0  #expected transitions 0->1\n",
    "            sum_correct_in_state1 = 0.0 #expected correct responses in state 1\n",
    "            sum_state1 = 0.0  #expected times in state 1\n",
    "            sum_correct_in_state0 = 0.0  #expected correct responses in state 0\n",
    "            sum_state0 = 0.0  # expected times in state 0\n",
    "\n",
    "            #E-step: compute expected counts\n",
    "            #iterate through all sequences\n",
    "            for seq in sequences:\n",
    "\n",
    "                #ignore if sequence length is zero\n",
    "                if len(seq) == 0:\n",
    "                    continue\n",
    "\n",
    "                #get results from forward-backward and update sums\n",
    "                alpha, beta, gamma, xi = self.forward_backward(seq)\n",
    "                len_seq = len(seq)\n",
    "                sum_init1 += gamma[0]\n",
    "                sum_gamma1 += gamma.sum()\n",
    "                sum_gamma0 += (len_seq - gamma.sum())\n",
    "                sum_trans_0_to_1 += xi.sum() #expected transitions\n",
    "                #expected observation counts\n",
    "                #for state1: expected number of times in state1 and response correct\n",
    "\n",
    "                #iterate through current sequence \n",
    "                for t, c in enumerate(seq):\n",
    "\n",
    "                    #update sums according to gamma_t (formulas for expected counts)\n",
    "                    if gamma[t] > 0:\n",
    "                        if c == 1:\n",
    "                            sum_correct_in_state1 += gamma[t]\n",
    "                        sum_state1 += gamma[t]\n",
    "                        sum_state0 += (1.0 - gamma[t])\n",
    "                        if c == 1:\n",
    "                            sum_correct_in_state0 += (1.0 - gamma[t])\n",
    "                    else:\n",
    "                        # gamma[t]==0 --> contribution to state0 only\n",
    "                        sum_state0 += 1.0\n",
    "                        if c == 1:\n",
    "                            sum_correct_in_state0 += 1.0\n",
    "\n",
    "            #M-step updates according to formulas \n",
    "            new_p_init = (sum_init1 / len(sequences)) if len(sequences) > 0 else self.p_init\n",
    "            new_p_trans = (sum_trans_0_to_1 / max(1e-8, sum_gamma0))  # expected transitions / expected times in 0\n",
    "            new_slip = 1.0 - (sum_correct_in_state1 / max(1e-8, sum_state1))\n",
    "            new_guess = (sum_correct_in_state0 / max(1e-8, sum_state0))\n",
    "            # clip to avoid degenerate values\n",
    "            self.p_init = float(min(max(new_p_init, 1e-6), 1-1e-6))\n",
    "            self.p_trans = float(min(max(new_p_trans, 1e-6), 1-1e-6))\n",
    "            self.slip = float(min(max(new_slip, 1e-6), 1-1e-6))\n",
    "            self.guess = float(min(max(new_guess, 1e-6), 1-1e-6))\n",
    "            #if telling print out the current vaues of the parameters\n",
    "            if telling:\n",
    "                print(f\"EM iter {it+1}: p_init={self.p_init:.5f}, p_trans={self.p_trans:.5f}, slip={self.slip:.5f}, guess={self.guess:.5f}\")\n",
    "\n",
    "    #predict posterior mastery after observed sequence P(L_T = 1 | observations seq)\n",
    "    def predict_mastery_after_sequence(self, seq):\n",
    "        #if no sequence, return initial mastery\n",
    "        if len(seq) == 0:\n",
    "            return self.p_init\n",
    "        #else return last gamma value from forward-backward (being in hidden state 1 after observing seq)\n",
    "        _, _, gamma, _ = self.forward_backward(seq)\n",
    "        return float(gamma[-1])\n",
    "\n",
    "    #Predict the probability of having the next response correct P(next response correct | observed seq).\n",
    "    def predict_next_correct_prob(self, seq):\n",
    "        p_mastery = self.predict_mastery_after_sequence(seq)\n",
    "        #basically just conditioning p_correct on p_mastery after the observed sequence \n",
    "        p_correct = p_mastery * (1.0 - self.slip) + (1.0 - p_mastery) * self.guess\n",
    "        return p_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8354d632",
   "metadata": {},
   "source": [
    "## Multi Skill BKT Model\n",
    "\n",
    "This is a extension to the previously defined simple BKT model that allows that multiple skills are needed for one task. It does so by multplying slip and guess chance conditioned on mastery for both skills (common practice). Additionally, it includes the following extensions to the vanilla BKT model:\n",
    "1. Incoperates difficulties by conditioning slip and guess on difficulty (Heffernan et al., 2011):\n",
    "* $P(p_{slip}\\mid task)$\n",
    "* $P(p_{guess}\\mid task)$\n",
    "2. Allows for multiple attempts after inital failure and conditions slip, guess and transition probabilite on this (Bhatt et al., 2020):\n",
    "* $P(p_{slip}\\mid \\# attempt)$\n",
    "* $P(p_{guess}\\mid \\# attempt)$\n",
    "* $P(p_{trans}\\mid \\# attempt)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2408cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for the BKT implementation which allows having multiple skills requrired in one task\n",
    "#includes:\n",
    "#   imediate retakes until correct or probabilistic retakes that condition slip, guess and transition probabilities\n",
    "#   task difficulties that condition slip and guess\n",
    "class MultiSkillBKT:\n",
    "\n",
    "    #initalize with n_skills BKT models\n",
    "    def __init__(self, n_skills: int, p_init=0.1, p_trans=0.1, slip=0.1, guess=0.2):\n",
    "        # Create one BKTModel per skill\n",
    "        self.skills = [BKTModel(p_init, p_trans, slip, guess) for _ in range(n_skills)]\n",
    "        self.n_skills = n_skills\n",
    "\n",
    "    \n",
    "    # Simulate a student sequence of responses for tasks, allowing retakes.\n",
    "    # Parameters:\n",
    "    #   - task_skill_map: List of tasks, each task is a list of skill indices needed for the task\n",
    "    #   - seed: random seed for reproducibility\n",
    "    #   - task_difficulties: Optional list of task difficulties (float) for each task\n",
    "    #   - retake_until_correct: if True, retry wrong attempts until correct or max_retries reached.\n",
    "    #   - max_retries: maximum number of attempts per task (including first attempt).\n",
    "\n",
    "    #returns a dictionary with keys:\n",
    "    #   - 'task' : index in task_skill_map\n",
    "    #   - 'attempt' : attempt number for that task (1,2,...) \n",
    "    #   - 'skills' : list of skill indices required for that task\n",
    "    #   - 'correct' : 0/1 whether the student answered correctly on that attempt\n",
    "    #   - 'difficulty' : difficulty of that task\n",
    "    def simulate_student(self, task_skill_map, seed = None, *, task_difficulties = None, retake_until_correct = False, max_retries = None):\n",
    "        \n",
    "        #set seed if given\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "\n",
    "        #set task difficulties to 1 if none given\n",
    "        if task_difficulties is None:\n",
    "            task_difficulties = [1.0 for _ in range(len(task_skill_map))]\n",
    "\n",
    "        # initialize per-skill mastery state based on p_init\n",
    "        L = [1 if random.random() < sk.p_init else 0 for sk in self.skills]\n",
    "        records: List[Dict[str, Any]] = []\n",
    "\n",
    "        for task_idx, skills_required in enumerate(task_skill_map):\n",
    "            attempt = 0\n",
    "            while True:\n",
    "                attempt += 1\n",
    "\n",
    "                # compute probability correct on this attempt (independent slip/guess per skill)\n",
    "                prob_correct = 1.0 \n",
    "\n",
    "                for s in skills_required:\n",
    "                    \n",
    "                    #condition slip and guess by difficulty\n",
    "                    effective_slip = min(max(self.skills[s].slip * task_difficulties[task_idx], 1e-6),1-1e-6)\n",
    "                    effective_guess = min(max(self.skills[s].guess / task_difficulties[task_idx], 1e-6),1-1e-6)\n",
    "\n",
    "                    #condition slip and guess by attempts \n",
    "                    SLIP_GUESS_STEP = 0.1\n",
    "                    effective_slip = min(max(effective_slip * (1 - SLIP_GUESS_STEP * (attempt - 1)), 1e-6), 1-1e-6)\n",
    "                    effective_guess = min(max(effective_guess * (1 + SLIP_GUESS_STEP * (attempt - 1)), 1e-6), 1-1e-6)\n",
    "\n",
    "                    #caluclate prob_correct contribution for that skill\n",
    "                    if L[s] == 1:\n",
    "                        prob_correct *= (1.0 - effective_slip)\n",
    "                    else:\n",
    "                        prob_correct *= effective_guess\n",
    "\n",
    "                #sample correctness for this attempt\n",
    "                if random.random() < prob_correct:\n",
    "                    c=1\n",
    "                else:\n",
    "                    c=0\n",
    "\n",
    "                #append current attempt record\n",
    "                records.append({\n",
    "                    'task': task_idx,\n",
    "                    'attempt': attempt,\n",
    "                    'skills': list(skills_required),\n",
    "                    'correct': c,\n",
    "                    'difficulty': task_difficulties[task_idx]\n",
    "                })\n",
    "\n",
    "                #after each attempt, update mastery for each skill (no forgetting)\n",
    "                for s in skills_required:\n",
    "\n",
    "                    P_TRANS_STEP = 0.1\n",
    "\n",
    "                    #condition p_trans on attempts\n",
    "                    effective_p_trans = min(self.skills[s].p_trans * (1 + P_TRANS_STEP * (attempt - 1)), 1 - 1e-6)\n",
    "\n",
    "                    if L[s] == 0 and random.random() < effective_p_trans:\n",
    "                        L[s] = 1\n",
    "\n",
    "                #decide whether to retry\n",
    "                if c == 1:\n",
    "                    break  #correct --> stop retrying (common policy)\n",
    "                # if incorrect retry until correct or max_retries reached \n",
    "                if retake_until_correct:\n",
    "                    if max_retries is None:\n",
    "                        continue\n",
    "                    elif attempt >= max_retries:\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    # no retakes if set to false\n",
    "                    break\n",
    "\n",
    "        return records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb6ede",
   "metadata": {},
   "source": [
    "## Example simulation\n",
    "\n",
    "Defines a task skill mapping and difficulties for each task. Afterwards initalizes a multi skill BKT and simulates a students behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429e0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task 0, attempt 1, skills [0], difficulty=0.6, correct=1\n",
      "task 1, attempt 1, skills [1], difficulty=1, correct=0\n",
      "task 1, attempt 2, skills [1], difficulty=1, correct=0\n",
      "task 1, attempt 3, skills [1], difficulty=1, correct=0\n",
      "task 1, attempt 4, skills [1], difficulty=1, correct=1\n",
      "task 2, attempt 1, skills [0, 1], difficulty=1, correct=1\n",
      "task 3, attempt 1, skills [0], difficulty=1, correct=1\n",
      "task 4, attempt 1, skills [1], difficulty=1, correct=1\n",
      "task 5, attempt 1, skills [0, 1], difficulty=1, correct=1\n",
      "task 6, attempt 1, skills [0], difficulty=1, correct=1\n",
      "task 7, attempt 1, skills [1], difficulty=1, correct=1\n",
      "task 8, attempt 1, skills [0, 1], difficulty=2, correct=0\n",
      "task 8, attempt 2, skills [0, 1], difficulty=2, correct=0\n",
      "task 8, attempt 3, skills [0, 1], difficulty=2, correct=1\n"
     ]
    }
   ],
   "source": [
    "#Example task mapping\n",
    "task_skill_map = [[0], [1], [0,1], [0], [1], [0,1], [0], [1], [0,1]]\n",
    "difficulties = [0.6, 1, 1, 1, 1, 1, 1, 1, 2]\n",
    "\n",
    "#initialize multi-skill BKT\n",
    "ms_bkt = MultiSkillBKT(n_skills=2, p_init=0.1, p_trans=0.1, slip=0.1, guess=0.2)\n",
    "\n",
    "# Example: retry until correct, up to 4 attempts\n",
    "records = ms_bkt.simulate_student(task_skill_map, task_difficulties=difficulties, seed=43, retake_until_correct=True)\n",
    "\n",
    "#output results \n",
    "for r in records:\n",
    "    print(f\"task {r['task']}, attempt {r['attempt']}, skills {r['skills']}, difficulty={r['difficulty']}, correct={r['correct']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Internship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
